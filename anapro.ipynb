{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from collections import namedtuple\n",
    "from datetime import datetime as dt\n",
    "import re\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'dateaubaseSandbox'\n",
    "local_server = r'GCI-PR-DATEAU01\\DATEAUBASE'\n",
    "remote_server = '10.10.10.10'\n",
    "path = \"sample_files\"\n",
    "with open('login.txt') as f:\n",
    "    username = f.readline().strip()\n",
    "    password = f.readline().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_local(server, database):\n",
    "    try:\n",
    "        engine = create_engine(f'mssql://{local_server}/{database_name}?trusted_connection=yes', fast_executemany=True)\n",
    "    except Exception as e:\n",
    "        print(\"local connection error\")\n",
    "        print(e)\n",
    "        return None\n",
    "    return engine\n",
    "\n",
    "\n",
    "def connect_remote(server, database):\n",
    "    try:\n",
    "        engine = create_engine(f'mssql+pyodbc://jeandavidt:koopa6425@{remote_server}:1433/{database_name}?driver=ODBC+Driver+13+for+SQL+Server', fast_executemany=True)\n",
    "        print('remote connection ok')\n",
    "    except Exception as e:\n",
    "        print(\"remote connection error\")\n",
    "        print(e)\n",
    "        return None\n",
    "    return engine\n",
    "\n",
    "\n",
    "def get_last(db_engine):\n",
    "    query = 'SELECT Value_ID, Timestamp FROM dbo.value WHERE Value_ID = (SELECT MAX(Value_ID) FROM dbo.value)'\n",
    "    result = db_engine.execute(query)\n",
    "    Record = namedtuple('record', result.keys())\n",
    "    records = [Record(*r) for r in result.fetchall()]\n",
    "    return records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_par_files(path):\n",
    "    full_path = os.path.join(os.getcwd(), path)\n",
    "\n",
    "    file_list = []\n",
    "    for file in os.listdir(full_path):\n",
    "        if file.endswith(\".par\"):\n",
    "            filename = os.path.join(full_path, file)\n",
    "            file_list.append(filename)\n",
    "\n",
    "    # Sort the list from the oldest to the last\n",
    "    file_list.sort\n",
    "\n",
    "    # Index of the oldest file with new data (will change during the execution but the last file always has new data)\n",
    "    index = len(file_list) - 1\n",
    "    return index, file_list\n",
    "\n",
    "\n",
    "def read_par(f_name, db_engine):\n",
    "    # load a file's data into a DataFrame\n",
    "    df = pd.read_csv(f_name, sep='\\t', skiprows=0, encoding='ANSI', header=1)\n",
    "\n",
    "    # Rename and select only the columns you need\n",
    "    new_cols = [\n",
    "        'Datetime', 'Status', 'TSS', 'TSSinfo',\n",
    "        'NO3N', 'NO3Ninfo', 'COD', 'CODinfo',\n",
    "        'CODf', 'CODfinfo', 'NH4N', 'NH4Ninfo',\n",
    "        'K', 'Kinfo', 'pH', 'pHinfo',\n",
    "        'Temp', 'Tempinfo'\n",
    "    ]\n",
    "    df.columns = new_cols\n",
    "    cols_to_keep = ['Datetime', 'TSS', 'NO3N', 'COD', 'CODf', 'NH4N', 'K', 'pH', 'Temp']\n",
    "    df = df[cols_to_keep]\n",
    "\n",
    "    # Fill the 'NaN' values\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # Convert the datetime strings into epoch time\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'], format='%Y.%m.%d  %H:%M:%S').dt.tz_localize('US/Eastern').astype(np.int64) // 10 ** 9\n",
    "\n",
    "    # Get the last ID from the database\n",
    "    last_ID, last_Timestamp = get_last(engine)\n",
    "\n",
    "    # Remove rows with a timestamp already in the dateaubase\n",
    "    time_mask = (df['Datetime'] > last_Timestamp)\n",
    "    df = df[time_mask]\n",
    "    if (not len(df)):\n",
    "        return None\n",
    "    # Stack the values into unique records\n",
    "    df.set_index('Datetime', inplace=True)\n",
    "    df = pd.DataFrame(df.stack())\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Rename the columns\n",
    "    df.columns = ['Timestamp', 'Metadata_ID', 'Value']\n",
    "\n",
    "    # Map the parameter names to the correct metadata_id\n",
    "    mapping = {\n",
    "        'TSS': 5,\n",
    "        'NO3N': 6,\n",
    "        'COD': 7,\n",
    "        'CODf': 8,\n",
    "        'NH4N': 1,\n",
    "        'K': 2,\n",
    "        'pH': 3,\n",
    "        'Temp': 4\n",
    "    }\n",
    "    df['Metadata_ID'] = df['Metadata_ID'].map(mapping)\n",
    "\n",
    "    # Apply a factor of 1000 for rows where Metadata_ID is 5, 6, 7 or 8\n",
    "    # These contain values for TSS, NO3, COD and CODf respectively\n",
    "    mask = (df['Metadata_ID'] > 4)\n",
    "    df.loc[mask, 'Value'] = df['Value'] / 1000\n",
    "\n",
    "    # Add 'Number of experiments column\n",
    "    df['Number_of_experiment'] = 1\n",
    "    df['Comment_ID'] = np.nan\n",
    "\n",
    "    # Add the lastID value plus increment to the index of the new values\n",
    "    df.index = df.index + last_ID + 1\n",
    "\n",
    "    # Turn index into regular column\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\n",
    "        'index': 'Value_ID'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # reorder columns\n",
    "    df = df[['Value_ID', 'Value', 'Number_of_experiment', 'Metadata_ID', 'Comment_ID', 'Timestamp']]\n",
    "\n",
    "    # And return result!\n",
    "    return df\n",
    "\n",
    "\n",
    "def send_to_db(df, db_engine):\n",
    "    # stores df in SQL table dbo.value\n",
    "    df.to_sql('value', con=db_engine, if_exists='append', index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(engine):\n",
    "    # Find the .par files on the path\n",
    "    index, file_list = get_par_files(path)\n",
    "\n",
    "    # get the latest timestamp on the dateaubase\n",
    "    _, last_Timestamp = get_last(engine)\n",
    "\n",
    "    # Convert the Timestamp in DateTime format\n",
    "    db_last_time = dt.fromtimestamp(last_Timestamp)\n",
    "\n",
    "    # loop to check all the files for data more recent than the last value in the db\n",
    "    for idx, file in enumerate(file_list):\n",
    "        with open(file, 'r') as f:\n",
    "            first_point_line = f.read().splitlines()[2]\n",
    "            first_time_string = re.split(r'\\t', first_point_line)[0]\n",
    "            file_first_time = dt.strptime(first_time_string, '%Y.%m.%d  %H:%M:%S')\n",
    "        # if a file is more recent than the last data => change the index to begin the import with the\n",
    "        # file just before this one\n",
    "        if file_first_time > db_last_time:\n",
    "            index = max(idx - 1, 0)\n",
    "            break\n",
    "\n",
    "    new_records = 0\n",
    "    for file in file_list[index:]:\n",
    "        new_data = read_par(file, engine)\n",
    "        if new_data is not None:\n",
    "            send_to_db(new_data, engine)\n",
    "            new_records += len(new_data)\n",
    "\n",
    "    print(f\"Added {new_records} rows to {database_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    engine = connect_remote(remote_server, database_name)\n",
    "    print('remote connection engine is running')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    main(engine)\n",
    "finally:\n",
    "    engine.dispose()"
   ]
  }
 ]
}